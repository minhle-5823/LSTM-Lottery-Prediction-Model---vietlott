{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Rn_MiuKmcvFR",
      "metadata": {
        "id": "Rn_MiuKmcvFR"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NZXcLY_DbKwo",
      "metadata": {
        "id": "NZXcLY_DbKwo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Updated imports for Functional API and Attention layer\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, AdditiveAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dLp41TdTr3vo",
      "metadata": {
        "id": "dLp41TdTr3vo"
      },
      "outputs": [],
      "source": [
        "# Model save file path\n",
        "MODEL_SAVE_PATH = 'best_lottery_lstm_model_attention.keras'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZdMIzIm2c1X-",
      "metadata": {
        "id": "ZdMIzIm2c1X-"
      },
      "source": [
        "# 1. DATA LOADING AND PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1hfEf1NbL7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "c1hfEf1NbL7f",
        "outputId": "0ff34017-c034-4c19-bdf7-d412d1d9359f"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('mega_6_45.csv')\n",
        "result_cols = ['num_1', 'num_2', 'num_3', 'num_4', 'num_5', 'num_6']\n",
        "results = df[result_cols].values\n",
        "\n",
        "# Number characteristics\n",
        "NUM_MAX = 45\n",
        "SEQUENCE_LENGTH = 10\n",
        "\n",
        "# >>> FEATURE PARAMETER DECLARATION <<<\n",
        "T_LOOKBACK = 5\n",
        "NUM_ADDITIONAL_FEATURES = 2\n",
        "NUM_TOTAL_FEATURES_FLAT = NUM_MAX * (1 + NUM_ADDITIONAL_FEATURES) # 45 * 3 = 135\n",
        "NUM_TOTAL_FEATURES = NUM_TOTAL_FEATURES_FLAT # Update this variable\n",
        "# -------------------------------------\n",
        "\n",
        "print(f\"Total number of historical draws: {len(results)}\")\n",
        "print(f\"Sequence length (timesteps) used: {SEQUENCE_LENGTH}\")\n",
        "\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "os-jdti9c8YH",
      "metadata": {
        "id": "os-jdti9c8YH"
      },
      "source": [
        "# 2. PREPROCESSING FUNCTION: ONE-HOT ENCODING & SEQUENCE GENERATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MhAW1z__bL-3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhAW1z__bL-3",
        "outputId": "78b793c9-c313-474c-e329-83422e364215"
      },
      "outputs": [],
      "source": [
        "def create_advanced_sequences(data, seq_length=SEQUENCE_LENGTH, num_max=NUM_MAX, T_lookback=T_LOOKBACK):\n",
        "    \"\"\"\n",
        "    Applies One-Hot Encoding and calculates advanced features (Recency, Frequency) \n",
        "    before generating time series sequences for LSTM.\n",
        "    \"\"\"\n",
        "    X, Y = [], []\n",
        "    num_samples = len(data)\n",
        "\n",
        "    # 1. One-Hot Encoding\n",
        "    one_hot_data = np.zeros((num_samples, num_max), dtype=int)\n",
        "    for i, row in enumerate(data):\n",
        "        one_hot_data[i, row - 1] = 1\n",
        "\n",
        "    # 2. Advanced Features\n",
        "    advanced_features = np.zeros((num_samples, num_max, NUM_ADDITIONAL_FEATURES))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Feature 1: Frequency in the last T draws\n",
        "        if i >= T_lookback:\n",
        "            recent_draws = data[i - T_lookback:i] # T draws BEFORE draw 'i'\n",
        "            counts = np.zeros(num_max, dtype=int)\n",
        "            for draw in recent_draws:\n",
        "                for num in draw:\n",
        "                    counts[num - 1] += 1\n",
        "            advanced_features[i, :, 0] = counts / (T_lookback * 6) # Normalization\n",
        "\n",
        "        # Feature 2: Coldness (Draws Since Last Drawn - DSLD)\n",
        "        for j in range(num_max):\n",
        "            num = j + 1\n",
        "            dsld = T_lookback * 2 # Default value (very cold)\n",
        "\n",
        "            # Find the most recent occurrence\n",
        "            for k in range(i-1, -1, -1):\n",
        "                if num in data[k]:\n",
        "                    dsld = i - k\n",
        "                    break\n",
        "\n",
        "            # Normalize DSLD: 1/(dsld+1) so smaller value means colder\n",
        "            advanced_features[i, j, 1] = 1.0 / (dsld + 1)\n",
        "\n",
        "    # 3. Combine features\n",
        "    full_feature_data = np.zeros((num_samples, num_max, 1 + NUM_ADDITIONAL_FEATURES))\n",
        "    full_feature_data[:, :, 0] = one_hot_data\n",
        "    full_feature_data[:, :, 1:] = advanced_features\n",
        "\n",
        "    # 4. Create sequences (Reshaping/Flattening)\n",
        "    for i in range(num_samples - seq_length):\n",
        "        seq_in = full_feature_data[i:i + seq_length]\n",
        "        seq_out = one_hot_data[i + seq_length]\n",
        "\n",
        "        # Flatten correctly: (seq_length, num_max * 3)\n",
        "        seq_in_flat = seq_in.reshape(seq_length, -1)\n",
        "\n",
        "        X.append(seq_in_flat)\n",
        "        Y.append(seq_out)\n",
        "\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# Generate data\n",
        "X, Y = create_advanced_sequences(results)\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"Y shape: {Y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XB8FmIxxdDEV",
      "metadata": {
        "id": "XB8FmIxxdDEV"
      },
      "source": [
        "# 3. TRAIN/VALIDATION/TEST SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apVs9SEWbMCf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apVs9SEWbMCf",
        "outputId": "db6ef8cc-23bc-4213-e1d5-cca55c6ab930"
      },
      "outputs": [],
      "source": [
        "test_size = int(len(X) * 0.2)\n",
        "X_train, X_test = X[:-test_size], X[-test_size:]\n",
        "Y_train, Y_test = Y[:-test_size], Y[-test_size:]\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    X_train, Y_train, test_size=0.1, shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Train set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IGsr_16sdG2g",
      "metadata": {
        "id": "IGsr_16sdG2g"
      },
      "source": [
        "# 4. METRIC DEFINITION AND DISTRIBUTION FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0FHfQc3sbMFQ",
      "metadata": {
        "id": "0FHfQc3sbMFQ"
      },
      "outputs": [],
      "source": [
        "def calculate_hits_array(y_true_one_hot, y_pred_prob):\n",
        "    \"\"\"\n",
        "    Calculates the number of correct hits for EACH draw (Top-6 prediction).\n",
        "    Returns an array of hit counts.\n",
        "    \"\"\"\n",
        "    # Get the indices of the 6 highest probability numbers (Top-6)\n",
        "    top_k_indices = np.argpartition(y_pred_prob, -6, axis=-1)[:, -6:]\n",
        "\n",
        "    # Create One-Hot prediction from Top-6 indices\n",
        "    y_pred_one_hot = np.zeros_like(y_true_one_hot)\n",
        "    for i, indices in enumerate(top_k_indices):\n",
        "        y_pred_one_hot[i, indices] = 1\n",
        "\n",
        "    # Count the number of hits for each draw\n",
        "    hits = np.sum(y_true_one_hot * y_pred_one_hot, axis=1)\n",
        "\n",
        "    return hits\n",
        "\n",
        "def print_hit_distribution(hits_array):\n",
        "    \"\"\"\n",
        "    Prints the detailed distribution of hits from 0 to 6.\n",
        "    \"\"\"\n",
        "    total_samples = len(hits_array)\n",
        "    hit_counts = Counter(hits_array)\n",
        "\n",
        "    print(\"\\n--- Hit Rate Distribution ---\")\n",
        "    for i in range(7): # From 0 hits up to 6 hits\n",
        "        count = hit_counts.get(i, 0)\n",
        "        percentage = (count / total_samples) * 100 if total_samples > 0 else 0\n",
        "        print(f\"    {i} hits: {count} times ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dCA5mI8edIOn",
      "metadata": {
        "id": "dCA5mI8edIOn"
      },
      "source": [
        "# 5. CALLBACK DEFINITION FOR PER-EPOCH EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XHF8uRkDbMHw",
      "metadata": {
        "id": "XHF8uRkDbMHw"
      },
      "outputs": [],
      "source": [
        "class HitRateCallback(Callback):\n",
        "    \"\"\"\n",
        "    Callback to calculate the average Hit-Rate (number of correct numbers) and \n",
        "    Hit-Ratio (0-1 scale) on the Validation set after each Epoch.\n",
        "    \"\"\"\n",
        "    def __init__(self, X_val, Y_val):\n",
        "        super().__init__()\n",
        "        self.X_val = X_val\n",
        "        self.Y_val = Y_val\n",
        "        # Note: If validation_data=(X_val, Y_val) is provided in model.fit,\n",
        "        # Keras automatically calculates val_loss before this callback runs.\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "\n",
        "        # 1. CALCULATE HIT RATE\n",
        "        y_val_pred = self.model.predict(self.X_val, verbose=0)\n",
        "        hits_array = calculate_hits_array(self.Y_val, y_val_pred)\n",
        "        avg_hit_rate_count = np.mean(hits_array)\n",
        "\n",
        "        # 2. UPDATE LOGS\n",
        "        logs['val_hit_count'] = avg_hit_rate_count\n",
        "        logs['val_hit_ratio'] = avg_hit_rate_count / 6 # Hit-Rate ratio (0-1)\n",
        "\n",
        "        # 3. OPTIONAL: Check and print val_loss\n",
        "        # val_loss is automatically logged if validation_data is provided"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fma079G5dMff",
      "metadata": {
        "id": "fma079G5dMff"
      },
      "source": [
        "# 6. LSTM MODEL CONSTRUCTION, TRAINING, AND SAVING"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jn5v4uVedbqW",
      "metadata": {
        "id": "jn5v4uVedbqW"
      },
      "source": [
        "## 6.1. Model Construction and Callback Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1WZ2xITcpBI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "a1WZ2xITcpBI",
        "outputId": "1640a35e-c04f-4e5b-a266-937a396eec5c"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(SEQUENCE_LENGTH, NUM_TOTAL_FEATURES_FLAT), name='input_sequence') # (10, 135)\n",
        "\n",
        "# 1. LSTM: Extract sequential features. MUST have return_sequences=True for Attention\n",
        "lstm_out = LSTM(256, return_sequences=True)(input_layer)\n",
        "lstm_out = Dropout(0.3)(lstm_out)\n",
        "\n",
        "# 2. Self-Attention Mechanism\n",
        "attention_output = AdditiveAttention(name='self_attention')([lstm_out, lstm_out]) # Key, Value, Query are lstm_out\n",
        "\n",
        "# 3. Aggregate information from Attention\n",
        "attention_pooled = GlobalAveragePooling1D()(attention_output)\n",
        "\n",
        "# 4. Final Dense classification layer\n",
        "dense_out = Dense(128, activation='relu')(attention_pooled)\n",
        "dense_out = Dropout(0.3)(dense_out)\n",
        "output_layer = Dense(NUM_MAX, activation='sigmoid', name='output_layer')(dense_out) # Output is 45 (for One-Hot)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# >>> IMPORTANT CHANGE: INITIALIZE CALLBACK AFTER X_VAL IS AVAILABLE <<<\n",
        "hit_rate_callback = HitRateCallback(X_val, Y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dVmMRhlAdl02",
      "metadata": {
        "id": "dVmMRhlAdl02"
      },
      "source": [
        "## 6.2. Training and Saving the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52fD_hDVbMKH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "52fD_hDVbMKH",
        "outputId": "be447257-34f2-41d0-a005-f8c829cd63d5"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Starting LSTM + ATTENTION Model Training ---\")\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    callbacks=[hit_rate_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"\\nModel saved successfully to: {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GppnlZRXtq1S",
      "metadata": {
        "id": "GppnlZRXtq1S"
      },
      "source": [
        "## 6.3. PROCESSING AND PRINTING TRAINING HISTORY RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BvKz0HRCto-L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvKz0HRCto-L",
        "outputId": "c3fde3aa-1a19-4053-ebe7-4207da831ba4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "if history is not None and history.history:\n",
        "    # Convert log history to DataFrame for easy processing\n",
        "    history_df = pd.DataFrame(history.history)\n",
        "    history_df.index.name = 'Epoch'\n",
        "    history_df.index = history_df.index + 1 # Epoch starts from 1\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"  PERFORMANCE SUMMARY ON VALIDATION SET AFTER TRAINING  \")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Calculate average over all epochs\n",
        "    avg_hit_count = history_df['val_hit_count'].mean()\n",
        "    avg_hit_ratio = history_df['val_hit_ratio'].mean()\n",
        "\n",
        "    print(f\"\\n  **Average results over all {len(history_df)} Epochs:**\")\n",
        "    print(f\"   | Avg val_hit_count : {avg_hit_count:>6.3f} correct numbers\")\n",
        "    print(f\"   | Avg val_hit_ratio : {avg_hit_ratio:>6.3f} ({avg_hit_ratio * 100:>6.2f}%)\")\n",
        "\n",
        "    # Best epoch (max val_hit_count)\n",
        "    best_epoch_index = history_df['val_hit_count'].idxmax()\n",
        "    best_hit_count = history_df.loc[best_epoch_index, 'val_hit_count']\n",
        "    best_hit_ratio = history_df.loc[best_epoch_index, 'val_hit_ratio']\n",
        "\n",
        "    print(f\"\\n  **Epoch with the Best Performance (Max Hit Count):**\")\n",
        "    print(f\"   | Epoch Index         : {best_epoch_index}\")\n",
        "    print(f\"   | Best val_hit_count  : {best_hit_count:>6.3f} correct numbers / 6\")\n",
        "    print(f\"   | Best val_hit_ratio  : {best_hit_ratio:>6.3f} ({best_hit_ratio * 100:>6.2f}%)\")\n",
        "\n",
        "    # Additional information (if other metrics exist)\n",
        "    if 'val_loss' in history_df.columns:\n",
        "        best_val_loss = history_df.loc[best_epoch_index, 'val_loss']\n",
        "        print(f\"\\n  **Validation Loss at best epoch:** {best_val_loss:.4f}\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"\\nWarning: Training history not found. Please check the `history` variable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Gd7DYjnwECh",
      "metadata": {
        "id": "1Gd7DYjnwECh"
      },
      "source": [
        "## 6.4. PLOTTING MODEL PERFORMANCE AFTER TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2DC3j7Z0wRl6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "2DC3j7Z0wRl6",
        "outputId": "0b0c25d7-dd7e-4e82-cd4c-1e4662675c72"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plots the training history for Loss (Train vs Validation) and Validation Hit Count.\n",
        "    \"\"\"\n",
        "    # Ensure data exists\n",
        "    if not history or not history.history:\n",
        "        print(\"No training history (history.history) found to plot.\")\n",
        "        return\n",
        "\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get values from the history object\n",
        "    loss = history_dict.get('loss')\n",
        "    val_loss = history_dict.get('val_loss')\n",
        "    val_hit_count = history_dict.get('val_hit_count')\n",
        "\n",
        "    if not loss:\n",
        "        print(\"Metric 'loss' not found in history.\")\n",
        "        return\n",
        "\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "\n",
        "    ## --- PLOT 1: LOSS (Train vs Validation) ---\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, 'b-', linewidth=2, label='Train Loss')\n",
        "\n",
        "    # Plot val_loss only if data exists\n",
        "    if val_loss is not None:\n",
        "        plt.plot(epochs, val_loss, 'r-', linewidth=2, label='Validation Loss')\n",
        "        # Mark the optimal point for Val Loss\n",
        "        min_val_loss = np.min(val_loss)\n",
        "        best_epoch_loss = np.argmin(val_loss) + 1\n",
        "        plt.plot(best_epoch_loss, min_val_loss, 'ro', markersize=5, label=f'Best Val Loss ({min_val_loss:.4f} @{best_epoch_loss})')\n",
        "\n",
        "    plt.title('Training and Validation Loss (Binary Crossentropy)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "\n",
        "    ## --- PLOT 2: VALIDATION HIT COUNT ---\n",
        "    if val_hit_count is not None:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, val_hit_count, 'g-', linewidth=2, label='Validation Hit Count')\n",
        "\n",
        "        # Add mean line\n",
        "        avg_hit = np.mean(val_hit_count)\n",
        "        plt.axhline(avg_hit, color='orange', linestyle='--', label=f'Avg Hit Count ({avg_hit:.2f})')\n",
        "\n",
        "        # Mark the best point for Hit Count\n",
        "        max_val_hit = np.max(val_hit_count)\n",
        "        best_epoch_hit = np.argmax(val_hit_count) + 1\n",
        "        plt.plot(best_epoch_hit, max_val_hit, 'go', markersize=5, label=f'Max Hit Count ({max_val_hit:.2f} @{best_epoch_hit})')\n",
        "\n",
        "        plt.title('Validation Hit Count (Avg Hits / 6)')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Average Number of Hits')\n",
        "        plt.ylim(bottom=0)\n",
        "        plt.legend(loc='lower left')\n",
        "        plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.suptitle('LSTM + ATTENTION MODEL TRAINING HISTORY ANALYSIS', fontsize=16, y=1.03)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history) # Call the function with the trained history object"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p_G2RUg8duAO",
      "metadata": {
        "id": "p_G2RUg8duAO"
      },
      "source": [
        "# 7. FINAL EVALUATION ON TEST SET AND DISTRIBUTION DISPLAY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qXtdA6QjbMMf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXtdA6QjbMMf",
        "outputId": "50401280-8638-45eb-bf2f-de60526ccc0e"
      },
      "outputs": [],
      "source": [
        "y_test_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "# 1. Calculate the array of hits per draw\n",
        "test_hits_array = calculate_hits_array(Y_test, y_test_pred)\n",
        "\n",
        "# 2. Calculate the average Hit-Rate\n",
        "final_avg_hit_rate = np.mean(test_hits_array)\n",
        "\n",
        "# 3. Print Hit Rate distribution\n",
        "print_hit_distribution(test_hits_array)\n",
        "\n",
        "print(\"\\n--- Performance Summary ---\")\n",
        "print(f\"Number of draws in Test set: {len(X_test)}\")\n",
        "print(f\"AVERAGE Hit-Rate on Test Set: {final_avg_hit_rate:.4f} correct numbers (out of 6)\")\n",
        "print(f\"Average correct prediction ratio per sequence: {(final_avg_hit_rate/6)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-W6kmgjldyJW",
      "metadata": {
        "id": "-W6kmgjldyJW"
      },
      "source": [
        "# 8. USING THE SAVED MODEL TO PREDICT BASED ON THE LATEST 10 DRAWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q-t0mi3DZJLy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-t0mi3DZJLy",
        "outputId": "e3ea61aa-bedf-4a3d-f498-513ec61aa5ff"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "NUM_MAX = 45 # Maximum number (1-45)\n",
        "SEQUENCE_LENGTH = 10 # Length of the input history sequence (Time Step Window)\n",
        "\n",
        "# Assume the following parameters match the training phase\n",
        "T_LOOKBACK = 5\n",
        "NUM_ADDITIONAL_FEATURES = 2\n",
        "NUM_TOTAL_FEATURES_FLAT = NUM_MAX * (1 + NUM_ADDITIONAL_FEATURES)\n",
        "\n",
        "\n",
        "try:\n",
        "    # Replace the path with your actual model file path\n",
        "    loaded_model = load_model('/content/best_lottery_lstm_model_attention.keras')\n",
        "    print(\"Successfully loaded the saved model.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    # loaded_model = model # Fallback if running immediately after training\n",
        "    # return\n",
        "\n",
        "\n",
        "# 1. Load full data (needed to get the entire history for feature calculation)\n",
        "df_full = pd.read_csv('mega_6_45.csv')\n",
        "result_cols = ['num_1', 'num_2', 'num_3', 'num_4', 'num_5', 'num_6']\n",
        "all_results = df_full[result_cols].values\n",
        "\n",
        "# 2. Create advanced sequences FROM ALL DATA\n",
        "# X_full will have shape (N_samples, 10, 135)\n",
        "# Re-use the function used for training\n",
        "X_full, _ = create_advanced_sequences(\n",
        "    all_results,\n",
        "    seq_length=SEQUENCE_LENGTH,\n",
        "    num_max=NUM_MAX,\n",
        "    T_lookback=T_LOOKBACK\n",
        ")\n",
        "\n",
        "# 3. Extract the last input (the input for the next draw)\n",
        "# new_input: (1, 10, 135)\n",
        "new_input = X_full[-1].reshape(1, SEQUENCE_LENGTH, NUM_TOTAL_FEATURES_FLAT)\n",
        "\n",
        "print(f\"New Input shape for prediction: {new_input.shape}\")\n",
        "\n",
        "# Predict probabilities\n",
        "predicted_prob = loaded_model.predict(new_input, verbose=0)[0]\n",
        "\n",
        "# Select the 6 numbers with the highest probability (Top-6)\n",
        "# Get indices of the 6 largest values\n",
        "predicted_indices = np.argsort(predicted_prob)[::-1][:6]\n",
        "# Convert indices (0-44) to numbers (1-45)\n",
        "predicted_numbers = predicted_indices + 1\n",
        "predicted_numbers.sort() # Sort for readability\n",
        "\n",
        "# Display the 6 highest probability numbers along with their probabilities\n",
        "top_6_results = pd.DataFrame({\n",
        "    'Number': predicted_numbers,\n",
        "    'Probability': predicted_prob[predicted_indices]\n",
        "}).sort_values(by='Probability', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(f\"Last historical data used: {df_full['date'].iloc[-SEQUENCE_LENGTH:].values}\")\n",
        "print(f\"\\n6 Numbers predicted by the LSTM model as most likely:\")\n",
        "print(f\"{predicted_numbers}\\n\")\n",
        "print(top_6_results.to_markdown(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
